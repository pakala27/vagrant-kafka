# Maintained by Ansible
listeners=PLAINTEXT://:{{kafkabroker.port_plaintext}}
zookeeper.connect={% for host in groups['zookeeper'] %}{% if loop.index > 1%},{% endif %}{{ host }}:{{zookeeper.clientPort}}{% endfor %}

log.dirs={{kafkabroker.datadir}}

broker.id={{kafkabroker.id}}

group.initial.rebalance.delay.ms: 0
log.retention.check.interval.ms: 300000
log.retention.hours: 168
log.segment.bytes: 1073741824
num.io.threads: 16
num.network.threads: 8
num.partitions: 2
num.recovery.threads.per.data.dir: 2
offsets.topic.replication.factor: 2
socket.receive.buffer.bytes: 102400
socket.request.max.bytes: 104857600
socket.send.buffer.bytes: 102400
transaction.state.log.min.isr: 2
transaction.state.log.replication.factor: 2
zookeeper.connection.timeout.ms: 6000
metric.reporters: io.confluent.metrics.reporter.ConfluentMetricsReporter
#confluent.metrics.reporter.bootstrap.servers: {{inventory_hostname}}:{{kafkabroker.port_plaintext}}
confluent.metrics.reporter.bootstrap.servers: {% for host in groups['broker'] %}{% if loop.index > 1%},{% endif %}{{ host }}:{{kafkabroker.port_plaintext}}{% endfor %}

confluent.metrics.reporter.topic.replicas: 2
ssl.endpoint.identification.algorithm: ""
confluent.metrics.reporter.ssl.endpoint.identification.algorithm: ""
delete.topic.enable: true

#Confluent Support
#confluent.support.metrics.enable={{confluent.support.metrics_enabled|bool|lower}}
#confluent.support.customer.id={{confluent.support.customer_id}}